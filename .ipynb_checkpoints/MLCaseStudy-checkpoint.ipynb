{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Patients with Abnormal Blood Pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/rahul/Sessions/Training Data - Classification of Patients with Abnormal Blood Pressure (N=2000)_27-Jul-2016.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-08e777ee6a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'/home/rahul/Sessions/Training Data - Classification of Patients with Abnormal Blood Pressure (N=2000)_27-Jul-2016.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/rahul/Sessions/Training Data - Classification of Patients with Abnormal Blood Pressure (N=2000)_27-Jul-2016.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train_path =  '/home/rahul/Sessions/Training Data - Classification of Patients with Abnormal Blood Pressure (N=2000)_27-Jul-2016.csv'\n",
    "train_df = pd.read_csv(train_path,',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the dimension of the data, along with the data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of data :\n",
      "(2000, 15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Dimension of data :')\n",
    "print(train_df.shape)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9919944dcd56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45961</td>\n",
       "      <td>48071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.23</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26106</td>\n",
       "      <td>25333</td>\n",
       "      <td>205.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.79</td>\n",
       "      <td>0.91</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9995</td>\n",
       "      <td>29465</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10635</td>\n",
       "      <td>7439</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15619</td>\n",
       "      <td>49644</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>27042</td>\n",
       "      <td>7513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38369</td>\n",
       "      <td>32967</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.41</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>29781</td>\n",
       "      <td>26749</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10.88</td>\n",
       "      <td>0.68</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>814</td>\n",
       "      <td>9607</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14.56</td>\n",
       "      <td>0.61</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1278</td>\n",
       "      <td>12715</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "0               1                           1                11.28   \n",
       "1               2                           0                 9.75   \n",
       "2               3                           1                10.79   \n",
       "3               4                           0                11.00   \n",
       "4               5                           1                14.17   \n",
       "5               6                           0                11.64   \n",
       "6               7                           1                11.69   \n",
       "7               8                           0                12.70   \n",
       "8               9                           0                10.88   \n",
       "9              10                           1                14.56   \n",
       "\n",
       "   Genetic_Pedigree_Coefficient  Age  BMI  Sex  Pregnancy  Smoking  \\\n",
       "0                          0.90   34   23    1        1.0        0   \n",
       "1                          0.23   54   33    1        NaN        0   \n",
       "2                          0.91   70   49    0        NaN        0   \n",
       "3                          0.43   71   50    0        NaN        0   \n",
       "4                          0.83   52   19    0        NaN        0   \n",
       "5                          0.54   23   48    0        NaN        1   \n",
       "6                          0.75   43   41    1        1.0        0   \n",
       "7                          0.41   48   20    0        NaN        0   \n",
       "8                          0.68   72   44    0        NaN        0   \n",
       "9                          0.61   40   44    0        NaN        0   \n",
       "\n",
       "   Physical_activity  salt_content_in_the_diet  alcohol_consumption_per_day  \\\n",
       "0              45961                     48071                          NaN   \n",
       "1              26106                     25333                        205.0   \n",
       "2               9995                     29465                         67.0   \n",
       "3              10635                      7439                        242.0   \n",
       "4              15619                     49644                        397.0   \n",
       "5              27042                      7513                          NaN   \n",
       "6              38369                     32967                        206.0   \n",
       "7              29781                     26749                        134.0   \n",
       "8                814                      9607                         99.0   \n",
       "9               1278                     12715                         95.0   \n",
       "\n",
       "   Level_of_Stress  Chronic_kidney_disease  Adrenal_and_thyroid_disorders  \n",
       "0                2                       1                              1  \n",
       "1                3                       0                              0  \n",
       "2                2                       1                              0  \n",
       "3                1                       1                              0  \n",
       "4                2                       0                              0  \n",
       "5                3                       0                              0  \n",
       "6                3                       1                              1  \n",
       "7                2                       0                              0  \n",
       "8                3                       0                              0  \n",
       "9                2                       0                              0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1758.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>11.710035</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>46.558500</td>\n",
       "      <td>30.081500</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.450226</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>25254.424500</td>\n",
       "      <td>24926.097000</td>\n",
       "      <td>251.008532</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>2.186701</td>\n",
       "      <td>0.291736</td>\n",
       "      <td>17.107832</td>\n",
       "      <td>11.761208</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>0.498080</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>14015.439623</td>\n",
       "      <td>14211.692586</td>\n",
       "      <td>143.651884</td>\n",
       "      <td>0.823822</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.147500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13605.750000</td>\n",
       "      <td>13151.750000</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25353.000000</td>\n",
       "      <td>25046.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.945000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37382.250000</td>\n",
       "      <td>36839.750000</td>\n",
       "      <td>377.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49980.000000</td>\n",
       "      <td>49976.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     2000.000000                 2000.000000          2000.000000   \n",
       "mean      1000.500000                    0.493500            11.710035   \n",
       "std        577.494589                    0.500083             2.186701   \n",
       "min          1.000000                    0.000000             8.100000   \n",
       "25%        500.750000                    0.000000            10.147500   \n",
       "50%       1000.500000                    0.000000            11.330000   \n",
       "75%       1500.250000                    1.000000            12.945000   \n",
       "max       2000.000000                    1.000000            17.560000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient          Age          BMI          Sex  \\\n",
       "count                   1908.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean                       0.494817    46.558500    30.081500     0.496000   \n",
       "std                        0.291736    17.107832    11.761208     0.500109   \n",
       "min                        0.000000    18.000000    10.000000     0.000000   \n",
       "25%                        0.240000    32.000000    20.000000     0.000000   \n",
       "50%                        0.490000    46.000000    30.000000     0.000000   \n",
       "75%                        0.740000    62.000000    40.000000     1.000000   \n",
       "max                        1.000000    75.000000    50.000000     1.000000   \n",
       "\n",
       "        Pregnancy      Smoking  Physical_activity  salt_content_in_the_diet  \\\n",
       "count  442.000000  2000.000000        2000.000000               2000.000000   \n",
       "mean     0.450226     0.509500       25254.424500              24926.097000   \n",
       "std      0.498080     0.500035       14015.439623              14211.692586   \n",
       "min      0.000000     0.000000         628.000000                 22.000000   \n",
       "25%      0.000000     0.000000       13605.750000              13151.750000   \n",
       "50%      0.000000     1.000000       25353.000000              25046.500000   \n",
       "75%      1.000000     1.000000       37382.250000              36839.750000   \n",
       "max      1.000000     1.000000       49980.000000              49976.000000   \n",
       "\n",
       "       alcohol_consumption_per_day  Level_of_Stress  Chronic_kidney_disease  \\\n",
       "count                  1758.000000      2000.000000               2000.0000   \n",
       "mean                    251.008532         2.012500                  0.5050   \n",
       "std                     143.651884         0.823822                  0.5001   \n",
       "min                       0.000000         1.000000                  0.0000   \n",
       "25%                     126.250000         1.000000                  0.0000   \n",
       "50%                     250.000000         2.000000                  1.0000   \n",
       "75%                     377.750000         3.000000                  1.0000   \n",
       "max                     499.000000         3.000000                  1.0000   \n",
       "\n",
       "       Adrenal_and_thyroid_disorders  \n",
       "count                    2000.000000  \n",
       "mean                        0.443500  \n",
       "std                         0.496922  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         1.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the current data description, there are few features from which data is missing like Genetic_Pedigree_Coefficient , Pregnancy etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if data is skewed or not ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>freqs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>1013</td>\n",
       "      <td>0.5065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abnormal</th>\n",
       "      <td>987</td>\n",
       "      <td>0.4935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            counts   freqs\n",
       "categories                \n",
       "Normal        1013  0.5065\n",
       "Abnormal       987  0.4935"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormality = pd.Categorical(train_df[\"Blood_Pressure_Abnormality\"])\n",
    "abnormality = abnormality.rename_categories([\"Normal\",\"Abnormal\"])\n",
    "abnormality.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data seems to be equally distributed in the 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  23,   44,   56,   68,   85,  102,  132,  149,  175,  187,  201,\n",
       "         227,  233,  247,  277,  292,  339,  352,  397,  432,  438,  460,\n",
       "         473,  491,  496,  503,  518,  526,  547,  565,  578,  652,  661,\n",
       "         670,  684,  753,  756,  792,  833,  843,  873,  878,  894,  903,\n",
       "         906,  925,  941,  944,  987, 1005, 1014, 1030, 1052, 1056, 1067,\n",
       "        1074, 1125, 1127, 1133, 1147, 1166, 1178, 1188, 1196, 1210, 1267,\n",
       "        1277, 1281, 1287, 1311, 1333, 1348, 1356, 1381, 1409, 1467, 1525,\n",
       "        1563, 1570, 1593, 1701, 1712, 1721, 1739, 1751, 1855, 1857, 1907,\n",
       "        1921, 1964, 1972, 1984]),)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fill_train_df = train_df.copy(deep=True)\n",
    "missing_Gen_Info = np.where(Fill_train_df[\"Genetic_Pedigree_Coefficient\"].isnull() == True)\n",
    "missing_Gen_Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_Gen_Info[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking for outliers.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff64d19a400>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.hist(column='Genetic_Pedigree_Coefficient',bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff64d0f2898>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.hist(column='Level_of_Hemoglobin',bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filling missing data.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.where(Fill_train_df[\"Genetic_Pedigree_Coefficient\"].isnull(), \n",
    "                       0.49,                    \n",
    "                       Fill_train_df[\"Genetic_Pedigree_Coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2000.000000\n",
       "mean        0.494595\n",
       "std         0.284945\n",
       "min         0.000000\n",
       "25%         0.250000\n",
       "50%         0.490000\n",
       "75%         0.730000\n",
       "max         1.000000\n",
       "Name: Genetic_Pedigree_Coefficient, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fill_train_df[\"Genetic_Pedigree_Coefficient\"] = gen \n",
    "\n",
    "Fill_train_df[\"Genetic_Pedigree_Coefficient\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff64d1dd6a0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fill_train_df.hist(column='Genetic_Pedigree_Coefficient',bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1908.000000\n",
       "mean        0.494817\n",
       "std         0.291736\n",
       "min         0.000000\n",
       "25%         0.240000\n",
       "50%         0.490000\n",
       "75%         0.740000\n",
       "max         1.000000\n",
       "Name: Genetic_Pedigree_Coefficient, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Genetic_Pedigree_Coefficient\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff64ce8c2e8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fill_train_df[\"Level_of_Hemoglobin\"].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff64cdf3b70>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fill_train_df[\"Genetic_Pedigree_Coefficient\"].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing whole rows with missing data.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above plot of Genetic_Pedigree_Coefficient that after filling the missing values with mean, it is more concentrated in the centre. As this may cause some problems while training, thus it is better to remove the whole records. The number of missing records are less than 5% thus it won't cause much issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_missinValues = train_df.copy(deep=True)\n",
    "train_df_missinValues = train_df_missinValues.loc[:,:'Genetic_Pedigree_Coefficient']\n",
    "train_df_missinValues = train_df_missinValues.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1908.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1003.972746</td>\n",
       "      <td>0.501572</td>\n",
       "      <td>11.706887</td>\n",
       "      <td>0.494817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>578.751254</td>\n",
       "      <td>0.500129</td>\n",
       "      <td>2.183418</td>\n",
       "      <td>0.291736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>502.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.140000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1003.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1507.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.925000</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.560000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     1908.000000                 1908.000000          1908.000000   \n",
       "mean      1003.972746                    0.501572            11.706887   \n",
       "std        578.751254                    0.500129             2.183418   \n",
       "min          1.000000                    0.000000             8.100000   \n",
       "25%        502.750000                    0.000000            10.140000   \n",
       "50%       1003.500000                    1.000000            11.330000   \n",
       "75%       1507.250000                    1.000000            12.925000   \n",
       "max       2000.000000                    1.000000            17.560000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient  \n",
       "count                   1908.000000  \n",
       "mean                       0.494817  \n",
       "std                        0.291736  \n",
       "min                        0.000000  \n",
       "25%                        0.240000  \n",
       "50%                        0.490000  \n",
       "75%                        0.740000  \n",
       "max                        1.000000  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_missinValues.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of two features i.e. Level of Hemoglobin and Genetic Pedigree Coefficient are not in same range, thus it can make training more complex. It will be good if both can come under the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_mv_norm = train_df_missinValues.copy(deep=True)\n",
    "lvlOfHg = np.array(train_df_mv_norm['Level_of_Hemoglobin'])\n",
    "scaler = MinMaxScaler().fit(lvlOfHg.reshape(-1, 1))\n",
    "rescaled = scaler.transform(lvlOfHg.reshape(-1, 1))\n",
    "\n",
    "train_df_mv_norm['Level_of_Hemoglobin'] = rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1908.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1003.972746</td>\n",
       "      <td>0.501572</td>\n",
       "      <td>0.381278</td>\n",
       "      <td>0.494817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>578.751254</td>\n",
       "      <td>0.500129</td>\n",
       "      <td>0.230805</td>\n",
       "      <td>0.291736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>502.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215645</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1003.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.341438</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1507.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510042</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     1908.000000                 1908.000000          1908.000000   \n",
       "mean      1003.972746                    0.501572             0.381278   \n",
       "std        578.751254                    0.500129             0.230805   \n",
       "min          1.000000                    0.000000             0.000000   \n",
       "25%        502.750000                    0.000000             0.215645   \n",
       "50%       1003.500000                    1.000000             0.341438   \n",
       "75%       1507.250000                    1.000000             0.510042   \n",
       "max       2000.000000                    1.000000             1.000000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient  \n",
       "count                   1908.000000  \n",
       "mean                       0.494817  \n",
       "std                        0.291736  \n",
       "min                        0.000000  \n",
       "25%                        0.240000  \n",
       "50%                        0.490000  \n",
       "75%                        0.740000  \n",
       "max                        1.000000  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_mv_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(train_df_mv_norm.iloc[:,1:])\n",
    "X, Y = data[:,1:],data[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Y = Y.reshape(Y.shape[0],)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    stratify=Y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using LR:\n",
    "- Simple and Linear\n",
    "- Not much parameters to tune\n",
    "\n",
    "Cons :\n",
    "- Cannot handle non - linearities\n",
    "- Cannot handle large number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.53\n",
      "Accuracy of Logistic regression classifier on test set: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(7)\n",
    "Y_train.reshape(1,Y_train.shape[0])\n",
    "Y_test.reshape(1,Y_test.shape[0])\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "testY_temp = logreg.predict(X_test)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, Y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using NB:\n",
    "- Easy and fast\n",
    "- Works good for categorical variables\n",
    "- Works well for multi class prediction.\n",
    "\n",
    "Cons :\n",
    "- If new category comes in the test data set, it fails to predict.\n",
    "- Requires independent variables, independent variables are rare in real life problems.\n",
    "\n",
    "Types :\n",
    "- Gaussian \n",
    "- Multinomial\n",
    "- Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB on training set: 0.86\n",
      "Accuracy of GaussianNB on test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GaussianNB on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GaussianNB on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.53\n",
      "Accuracy of Logistic regression classifier on test set: 0.55\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'solver':('newton-cg', 'lbfgs', 'sag', 'saga')}\n",
    "classifier = LogisticRegression()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using DT:\n",
    "- Uses decision rules.\n",
    "- Can handle non linear data.\n",
    "- Takes into account variable interaction.\n",
    "\n",
    "Cons :\n",
    "- Biased on training set.\n",
    "- Overfits the training set.\n",
    "- No ranking score, direct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, Y_train)\n",
    "testY_temp = classifier.predict(X_test)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(classifier.score(X_train, Y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(classifier.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.84\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'criterion':('gini','entropy'),'max_features':(None,'auto','sqrt','log2')}\n",
    "classifier = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using RF:\n",
    "- Single decision tree tends to overfit the data. The process of averaging or combining the results of different decision trees helps to overcome the problem of overfitting.\n",
    "- Works good for large range of data.\n",
    "- Scaling is not necesary.\n",
    "- Maintains accuracy even though data is missing.\n",
    "\n",
    "Cons :\n",
    "- Complex\n",
    "- Time consuming\n",
    "- Requires more computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier on training set: 0.99\n",
      "Accuracy of RandomForestClassifier on test set: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "testY_temp = classifier.predict(X_test)\n",
    "print('Accuracy of RandomForestClassifier on training set: {:.2f}'\n",
    "     .format(classifier.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForestClassifier on test set: {:.2f}'\n",
    "     .format(classifier.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier on training set: 1.00\n",
      "Accuracy of RandomForestClassifier on test set: 0.88\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "parameters = {'n_estimators':[10,50,100],'criterion':('gini','entropy'),'max_features':(None,'auto','sqrt','log2')}\n",
    "classifier = RandomForestClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of RandomForestClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForestClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using GB:\n",
    "- Builds each tree sequentially.\n",
    "- Each new tree helps to correct errors made by previously trained tree. \n",
    "- Better learner than RF.\n",
    "\n",
    "Cons :\n",
    "- Prone to overfitting.\n",
    "- Many parameters to tune.\n",
    "- Not very speedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GradientBoostingClassifier on training set: 0.92\n",
      "Accuracy of GradientBoostingClassifier on test set: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train, Y_train)\n",
    "testY_temp = classifier.predict(X_test)\n",
    "print('Accuracy of GradientBoostingClassifier on training set: {:.2f}'\n",
    "     .format(classifier.score(X_train, Y_train)))\n",
    "print('Accuracy of GradientBoostingClassifier on test set: {:.2f}'\n",
    "     .format(classifier.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GradientBoostingClassifier on training set: 0.92\n",
      "Accuracy of GradientBoostingClassifier on test set: 0.90\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features='log2', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "parameters = {'n_estimators':[50,100,150,250],'loss' : ('deviance', 'exponential'),'max_features':('auto','sqrt','log2')}\n",
    "classifier = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GradientBoostingClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GradientBoostingClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using KNN:\n",
    "- Simple to implement\n",
    "- Flexible to feature / distance choices\n",
    "- Effective if training data is large\n",
    "\n",
    "Cons :\n",
    "- Computation is quite high.\n",
    "- Need to know no of nearest neighbours.\n",
    "- Must know we have a meaningful distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNeighborsClassifier on training set: 0.91\n",
      "Accuracy of KNeighborsClassifier on test set: 0.90\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "parameters = {'n_neighbors':[3,5,7,10]}\n",
    "classifier = KNeighborsClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of KNeighborsClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of KNeighborsClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using SVM:\n",
    "- Can handle large feature space\n",
    "- Can handle non-linear feature interactions\n",
    "- Do not rely on entire data\n",
    "\n",
    "Cons :\n",
    "- Computation is quite high.\n",
    "- It can be tricky to find appropriate kernel sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm on training set: 0.88\n",
      "Accuracy of svm on test set: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of svm on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of svm on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm on training set: 0.92\n",
      "Accuracy of svm on test set: 0.91\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'kernel' : ('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "classifier = svm.SVC()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of svm on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of svm on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using MLP:\n",
    "- Can solve complex problems\n",
    "- Can learn non-linear and complex problems\n",
    "- After learning from the initial inputs and their relationships, it can infer unseen relationships on unseen data as well, thus making the model generalize and predict on unseen data.\n",
    "\n",
    "Cons :\n",
    "- Training time is high\n",
    "- Many parameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of mlp on training set: 0.91\n",
      "Accuracy of mlp on test set: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "np.random.seed(7)\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of mlp on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of mlp on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of mlp on training set: 0.92\n",
      "Accuracy of mlp on test set: 0.90\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "parameters = {'activation' : ('logistic', 'tanh', 'relu'),'solver' : ('sgd', 'adam')}\n",
    "classifier = MLPClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of mlp on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of mlp on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with more features.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_train_df = train_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1758.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>11.710035</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>46.558500</td>\n",
       "      <td>30.081500</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.450226</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>25254.424500</td>\n",
       "      <td>24926.097000</td>\n",
       "      <td>251.008532</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>2.186701</td>\n",
       "      <td>0.291736</td>\n",
       "      <td>17.107832</td>\n",
       "      <td>11.761208</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>0.498080</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>14015.439623</td>\n",
       "      <td>14211.692586</td>\n",
       "      <td>143.651884</td>\n",
       "      <td>0.823822</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.147500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13605.750000</td>\n",
       "      <td>13151.750000</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25353.000000</td>\n",
       "      <td>25046.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.945000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37382.250000</td>\n",
       "      <td>36839.750000</td>\n",
       "      <td>377.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49980.000000</td>\n",
       "      <td>49976.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     2000.000000                 2000.000000          2000.000000   \n",
       "mean      1000.500000                    0.493500            11.710035   \n",
       "std        577.494589                    0.500083             2.186701   \n",
       "min          1.000000                    0.000000             8.100000   \n",
       "25%        500.750000                    0.000000            10.147500   \n",
       "50%       1000.500000                    0.000000            11.330000   \n",
       "75%       1500.250000                    1.000000            12.945000   \n",
       "max       2000.000000                    1.000000            17.560000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient          Age          BMI          Sex  \\\n",
       "count                   1908.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean                       0.494817    46.558500    30.081500     0.496000   \n",
       "std                        0.291736    17.107832    11.761208     0.500109   \n",
       "min                        0.000000    18.000000    10.000000     0.000000   \n",
       "25%                        0.240000    32.000000    20.000000     0.000000   \n",
       "50%                        0.490000    46.000000    30.000000     0.000000   \n",
       "75%                        0.740000    62.000000    40.000000     1.000000   \n",
       "max                        1.000000    75.000000    50.000000     1.000000   \n",
       "\n",
       "        Pregnancy      Smoking  Physical_activity  salt_content_in_the_diet  \\\n",
       "count  442.000000  2000.000000        2000.000000               2000.000000   \n",
       "mean     0.450226     0.509500       25254.424500              24926.097000   \n",
       "std      0.498080     0.500035       14015.439623              14211.692586   \n",
       "min      0.000000     0.000000         628.000000                 22.000000   \n",
       "25%      0.000000     0.000000       13605.750000              13151.750000   \n",
       "50%      0.000000     1.000000       25353.000000              25046.500000   \n",
       "75%      1.000000     1.000000       37382.250000              36839.750000   \n",
       "max      1.000000     1.000000       49980.000000              49976.000000   \n",
       "\n",
       "       alcohol_consumption_per_day  Level_of_Stress  Chronic_kidney_disease  \\\n",
       "count                  1758.000000      2000.000000               2000.0000   \n",
       "mean                    251.008532         2.012500                  0.5050   \n",
       "std                     143.651884         0.823822                  0.5001   \n",
       "min                       0.000000         1.000000                  0.0000   \n",
       "25%                     126.250000         1.000000                  0.0000   \n",
       "50%                     250.000000         2.000000                  1.0000   \n",
       "75%                     377.750000         3.000000                  1.0000   \n",
       "max                     499.000000         3.000000                  1.0000   \n",
       "\n",
       "       Adrenal_and_thyroid_disorders  \n",
       "count                    2000.000000  \n",
       "mean                        0.443500  \n",
       "std                         0.496922  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         1.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "menP = np.where(AF_train_df[\"Sex\"]== 0, \n",
    "                       0,                    \n",
    "                       AF_train_df[\"Pregnancy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_train_df[\"Pregnancy\"] = menP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1450.000000\n",
       "mean        0.137241\n",
       "std         0.344221\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: Pregnancy, dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df[\"Pregnancy\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "womenP = np.where((AF_train_df[\"Sex\"]== 1) & (AF_train_df[\"Pregnancy\"].isnull()), \n",
    "                       2,                    \n",
    "                       AF_train_df[\"Pregnancy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0., ..., 0., 2., 0.])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "womenP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_train_df[\"Pregnancy\"] = womenP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1758.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>11.710035</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>46.558500</td>\n",
       "      <td>30.081500</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>25254.424500</td>\n",
       "      <td>24926.097000</td>\n",
       "      <td>251.008532</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>2.186701</td>\n",
       "      <td>0.291736</td>\n",
       "      <td>17.107832</td>\n",
       "      <td>11.761208</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>0.882065</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>14015.439623</td>\n",
       "      <td>14211.692586</td>\n",
       "      <td>143.651884</td>\n",
       "      <td>0.823822</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.147500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13605.750000</td>\n",
       "      <td>13151.750000</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25353.000000</td>\n",
       "      <td>25046.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.945000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37382.250000</td>\n",
       "      <td>36839.750000</td>\n",
       "      <td>377.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49980.000000</td>\n",
       "      <td>49976.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     2000.000000                 2000.000000          2000.000000   \n",
       "mean      1000.500000                    0.493500            11.710035   \n",
       "std        577.494589                    0.500083             2.186701   \n",
       "min          1.000000                    0.000000             8.100000   \n",
       "25%        500.750000                    0.000000            10.147500   \n",
       "50%       1000.500000                    0.000000            11.330000   \n",
       "75%       1500.250000                    1.000000            12.945000   \n",
       "max       2000.000000                    1.000000            17.560000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient          Age          BMI          Sex  \\\n",
       "count                   1908.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean                       0.494817    46.558500    30.081500     0.496000   \n",
       "std                        0.291736    17.107832    11.761208     0.500109   \n",
       "min                        0.000000    18.000000    10.000000     0.000000   \n",
       "25%                        0.240000    32.000000    20.000000     0.000000   \n",
       "50%                        0.490000    46.000000    30.000000     0.000000   \n",
       "75%                        0.740000    62.000000    40.000000     1.000000   \n",
       "max                        1.000000    75.000000    50.000000     1.000000   \n",
       "\n",
       "         Pregnancy      Smoking  Physical_activity  salt_content_in_the_diet  \\\n",
       "count  2000.000000  2000.000000        2000.000000               2000.000000   \n",
       "mean      0.649500     0.509500       25254.424500              24926.097000   \n",
       "std       0.882065     0.500035       14015.439623              14211.692586   \n",
       "min       0.000000     0.000000         628.000000                 22.000000   \n",
       "25%       0.000000     0.000000       13605.750000              13151.750000   \n",
       "50%       0.000000     1.000000       25353.000000              25046.500000   \n",
       "75%       2.000000     1.000000       37382.250000              36839.750000   \n",
       "max       2.000000     1.000000       49980.000000              49976.000000   \n",
       "\n",
       "       alcohol_consumption_per_day  Level_of_Stress  Chronic_kidney_disease  \\\n",
       "count                  1758.000000      2000.000000               2000.0000   \n",
       "mean                    251.008532         2.012500                  0.5050   \n",
       "std                     143.651884         0.823822                  0.5001   \n",
       "min                       0.000000         1.000000                  0.0000   \n",
       "25%                     126.250000         1.000000                  0.0000   \n",
       "50%                     250.000000         2.000000                  1.0000   \n",
       "75%                     377.750000         3.000000                  1.0000   \n",
       "max                     499.000000         3.000000                  1.0000   \n",
       "\n",
       "       Adrenal_and_thyroid_disorders  \n",
       "count                    2000.000000  \n",
       "mean                        0.443500  \n",
       "std                         0.496922  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         1.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Patient_Number</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021430</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>-0.005239</td>\n",
       "      <td>-0.030827</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>-0.004767</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.016808</td>\n",
       "      <td>0.022992</td>\n",
       "      <td>-0.025756</td>\n",
       "      <td>-0.013779</td>\n",
       "      <td>0.030543</td>\n",
       "      <td>0.004823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <td>0.021430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139488</td>\n",
       "      <td>-0.033458</td>\n",
       "      <td>-0.066322</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.037952</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.020773</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.429188</td>\n",
       "      <td>0.318598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.139488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023621</td>\n",
       "      <td>-0.184394</td>\n",
       "      <td>0.117889</td>\n",
       "      <td>-0.412928</td>\n",
       "      <td>-0.381110</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>-0.026604</td>\n",
       "      <td>0.022141</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.030384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <td>-0.005239</td>\n",
       "      <td>-0.033458</td>\n",
       "      <td>-0.023621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022164</td>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>-0.036887</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>-0.021080</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.041523</td>\n",
       "      <td>0.008336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.030827</td>\n",
       "      <td>-0.066322</td>\n",
       "      <td>-0.184394</td>\n",
       "      <td>-0.022164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.057941</td>\n",
       "      <td>0.409957</td>\n",
       "      <td>0.025314</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>-0.045740</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>-0.057540</td>\n",
       "      <td>-0.025738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.117889</td>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010219</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>-0.004936</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>-0.040780</td>\n",
       "      <td>-0.010689</td>\n",
       "      <td>0.012221</td>\n",
       "      <td>0.041061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>-0.412928</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.057941</td>\n",
       "      <td>0.010219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742440</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.026082</td>\n",
       "      <td>-0.011981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pregnancy</th>\n",
       "      <td>-0.004767</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>-0.381110</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>0.409957</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.742440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>-0.026835</td>\n",
       "      <td>-0.015018</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>-0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoking</th>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>-0.036887</td>\n",
       "      <td>0.025314</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.025196</td>\n",
       "      <td>0.018267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical_activity</th>\n",
       "      <td>0.016808</td>\n",
       "      <td>0.037952</td>\n",
       "      <td>-0.026604</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>-0.004936</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032261</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>-0.033700</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <td>0.022992</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.022141</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>-0.045740</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>-0.009347</td>\n",
       "      <td>-0.026835</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>-0.032261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029873</td>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.002856</td>\n",
       "      <td>0.019965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <td>-0.025756</td>\n",
       "      <td>0.020773</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>-0.021080</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>-0.040780</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>-0.015018</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>-0.029873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>-0.009832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <td>-0.013779</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>-0.010689</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.033700</td>\n",
       "      <td>-0.019268</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>-0.015993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <td>0.030543</td>\n",
       "      <td>0.429188</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.041523</td>\n",
       "      <td>-0.057540</td>\n",
       "      <td>0.012221</td>\n",
       "      <td>0.026082</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>-0.025196</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>-0.002856</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.318598</td>\n",
       "      <td>0.030384</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>-0.025738</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>-0.040067</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>-0.009832</td>\n",
       "      <td>-0.015993</td>\n",
       "      <td>0.118897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Patient_Number  Blood_Pressure_Abnormality  \\\n",
       "Patient_Number                       1.000000                    0.021430   \n",
       "Blood_Pressure_Abnormality           0.021430                    1.000000   \n",
       "Level_of_Hemoglobin                 -0.001083                    0.139488   \n",
       "Genetic_Pedigree_Coefficient        -0.005239                   -0.033458   \n",
       "Age                                 -0.030827                   -0.066322   \n",
       "BMI                                 -0.000281                    0.040193   \n",
       "Sex                                  0.023494                    0.054902   \n",
       "Pregnancy                           -0.004767                    0.033958   \n",
       "Smoking                              0.022939                    0.012250   \n",
       "Physical_activity                    0.016808                    0.037952   \n",
       "salt_content_in_the_diet             0.022992                    0.014199   \n",
       "alcohol_consumption_per_day         -0.025756                    0.020773   \n",
       "Level_of_Stress                     -0.013779                    0.009304   \n",
       "Chronic_kidney_disease               0.030543                    0.429188   \n",
       "Adrenal_and_thyroid_disorders        0.004823                    0.318598   \n",
       "\n",
       "                               Level_of_Hemoglobin  \\\n",
       "Patient_Number                           -0.001083   \n",
       "Blood_Pressure_Abnormality                0.139488   \n",
       "Level_of_Hemoglobin                       1.000000   \n",
       "Genetic_Pedigree_Coefficient             -0.023621   \n",
       "Age                                      -0.184394   \n",
       "BMI                                       0.117889   \n",
       "Sex                                      -0.412928   \n",
       "Pregnancy                                -0.381110   \n",
       "Smoking                                   0.023349   \n",
       "Physical_activity                        -0.026604   \n",
       "salt_content_in_the_diet                  0.022141   \n",
       "alcohol_consumption_per_day               0.007865   \n",
       "Level_of_Stress                           0.004746   \n",
       "Chronic_kidney_disease                    0.055262   \n",
       "Adrenal_and_thyroid_disorders             0.030384   \n",
       "\n",
       "                               Genetic_Pedigree_Coefficient       Age  \\\n",
       "Patient_Number                                    -0.005239 -0.030827   \n",
       "Blood_Pressure_Abnormality                        -0.033458 -0.066322   \n",
       "Level_of_Hemoglobin                               -0.023621 -0.184394   \n",
       "Genetic_Pedigree_Coefficient                       1.000000 -0.022164   \n",
       "Age                                               -0.022164  1.000000   \n",
       "BMI                                               -0.010230  0.028151   \n",
       "Sex                                                0.023103  0.057941   \n",
       "Pregnancy                                          0.034063  0.409957   \n",
       "Smoking                                           -0.036887  0.025314   \n",
       "Physical_activity                                 -0.007651  0.027068   \n",
       "salt_content_in_the_diet                           0.039028 -0.045740   \n",
       "alcohol_consumption_per_day                       -0.021080  0.017619   \n",
       "Level_of_Stress                                    0.012933  0.014057   \n",
       "Chronic_kidney_disease                             0.041523 -0.057540   \n",
       "Adrenal_and_thyroid_disorders                      0.008336 -0.025738   \n",
       "\n",
       "                                    BMI       Sex  Pregnancy   Smoking  \\\n",
       "Patient_Number                -0.000281  0.023494  -0.004767  0.022939   \n",
       "Blood_Pressure_Abnormality     0.040193  0.054902   0.033958  0.012250   \n",
       "Level_of_Hemoglobin            0.117889 -0.412928  -0.381110  0.023349   \n",
       "Genetic_Pedigree_Coefficient  -0.010230  0.023103   0.034063 -0.036887   \n",
       "Age                            0.028151  0.057941   0.409957  0.025314   \n",
       "BMI                            1.000000  0.010219   0.024454  0.008927   \n",
       "Sex                            0.010219  1.000000   0.742440 -0.000848   \n",
       "Pregnancy                      0.024454  0.742440   1.000000  0.000181   \n",
       "Smoking                        0.008927 -0.000848   0.000181  1.000000   \n",
       "Physical_activity             -0.004936  0.006297   0.024385 -0.014974   \n",
       "salt_content_in_the_diet       0.026385 -0.009347  -0.026835  0.003364   \n",
       "alcohol_consumption_per_day   -0.040780  0.004416  -0.015018  0.008671   \n",
       "Level_of_Stress               -0.010689  0.000729   0.019801 -0.026398   \n",
       "Chronic_kidney_disease         0.012221  0.026082   0.018150 -0.025196   \n",
       "Adrenal_and_thyroid_disorders  0.041061 -0.011981  -0.040067  0.018267   \n",
       "\n",
       "                               Physical_activity  salt_content_in_the_diet  \\\n",
       "Patient_Number                          0.016808                  0.022992   \n",
       "Blood_Pressure_Abnormality              0.037952                  0.014199   \n",
       "Level_of_Hemoglobin                    -0.026604                  0.022141   \n",
       "Genetic_Pedigree_Coefficient           -0.007651                  0.039028   \n",
       "Age                                     0.027068                 -0.045740   \n",
       "BMI                                    -0.004936                  0.026385   \n",
       "Sex                                     0.006297                 -0.009347   \n",
       "Pregnancy                               0.024385                 -0.026835   \n",
       "Smoking                                -0.014974                  0.003364   \n",
       "Physical_activity                       1.000000                 -0.032261   \n",
       "salt_content_in_the_diet               -0.032261                  1.000000   \n",
       "alcohol_consumption_per_day            -0.011322                 -0.029873   \n",
       "Level_of_Stress                        -0.033700                 -0.019268   \n",
       "Chronic_kidney_disease                  0.003938                 -0.002856   \n",
       "Adrenal_and_thyroid_disorders           0.000883                  0.019965   \n",
       "\n",
       "                               alcohol_consumption_per_day  Level_of_Stress  \\\n",
       "Patient_Number                                   -0.025756        -0.013779   \n",
       "Blood_Pressure_Abnormality                        0.020773         0.009304   \n",
       "Level_of_Hemoglobin                               0.007865         0.004746   \n",
       "Genetic_Pedigree_Coefficient                     -0.021080         0.012933   \n",
       "Age                                               0.017619         0.014057   \n",
       "BMI                                              -0.040780        -0.010689   \n",
       "Sex                                               0.004416         0.000729   \n",
       "Pregnancy                                        -0.015018         0.019801   \n",
       "Smoking                                           0.008671        -0.026398   \n",
       "Physical_activity                                -0.011322        -0.033700   \n",
       "salt_content_in_the_diet                         -0.029873        -0.019268   \n",
       "alcohol_consumption_per_day                       1.000000         0.014852   \n",
       "Level_of_Stress                                   0.014852         1.000000   \n",
       "Chronic_kidney_disease                            0.024967         0.018669   \n",
       "Adrenal_and_thyroid_disorders                    -0.009832        -0.015993   \n",
       "\n",
       "                               Chronic_kidney_disease  \\\n",
       "Patient_Number                               0.030543   \n",
       "Blood_Pressure_Abnormality                   0.429188   \n",
       "Level_of_Hemoglobin                          0.055262   \n",
       "Genetic_Pedigree_Coefficient                 0.041523   \n",
       "Age                                         -0.057540   \n",
       "BMI                                          0.012221   \n",
       "Sex                                          0.026082   \n",
       "Pregnancy                                    0.018150   \n",
       "Smoking                                     -0.025196   \n",
       "Physical_activity                            0.003938   \n",
       "salt_content_in_the_diet                    -0.002856   \n",
       "alcohol_consumption_per_day                  0.024967   \n",
       "Level_of_Stress                              0.018669   \n",
       "Chronic_kidney_disease                       1.000000   \n",
       "Adrenal_and_thyroid_disorders                0.118897   \n",
       "\n",
       "                               Adrenal_and_thyroid_disorders  \n",
       "Patient_Number                                      0.004823  \n",
       "Blood_Pressure_Abnormality                          0.318598  \n",
       "Level_of_Hemoglobin                                 0.030384  \n",
       "Genetic_Pedigree_Coefficient                        0.008336  \n",
       "Age                                                -0.025738  \n",
       "BMI                                                 0.041061  \n",
       "Sex                                                -0.011981  \n",
       "Pregnancy                                          -0.040067  \n",
       "Smoking                                             0.018267  \n",
       "Physical_activity                                   0.000883  \n",
       "salt_content_in_the_diet                            0.019965  \n",
       "alcohol_consumption_per_day                        -0.009832  \n",
       "Level_of_Stress                                    -0.015993  \n",
       "Chronic_kidney_disease                              0.118897  \n",
       "Adrenal_and_thyroid_disorders                       1.000000  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "alc_con = np.where(AF_train_df[\"alcohol_consumption_per_day\"].isnull(), \n",
    "                       250,                    \n",
    "                       AF_train_df[\"alcohol_consumption_per_day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_train_df[\"alcohol_consumption_per_day\"] = alc_con "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1908.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>11.710035</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>46.558500</td>\n",
       "      <td>30.081500</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>25254.424500</td>\n",
       "      <td>24926.097000</td>\n",
       "      <td>250.886500</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>2.186701</td>\n",
       "      <td>0.291736</td>\n",
       "      <td>17.107832</td>\n",
       "      <td>11.761208</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>0.882065</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>14015.439623</td>\n",
       "      <td>14211.692586</td>\n",
       "      <td>134.676589</td>\n",
       "      <td>0.823822</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.147500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13605.750000</td>\n",
       "      <td>13151.750000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25353.000000</td>\n",
       "      <td>25046.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.945000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37382.250000</td>\n",
       "      <td>36839.750000</td>\n",
       "      <td>360.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49980.000000</td>\n",
       "      <td>49976.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     2000.000000                 2000.000000          2000.000000   \n",
       "mean      1000.500000                    0.493500            11.710035   \n",
       "std        577.494589                    0.500083             2.186701   \n",
       "min          1.000000                    0.000000             8.100000   \n",
       "25%        500.750000                    0.000000            10.147500   \n",
       "50%       1000.500000                    0.000000            11.330000   \n",
       "75%       1500.250000                    1.000000            12.945000   \n",
       "max       2000.000000                    1.000000            17.560000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient          Age          BMI          Sex  \\\n",
       "count                   1908.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean                       0.494817    46.558500    30.081500     0.496000   \n",
       "std                        0.291736    17.107832    11.761208     0.500109   \n",
       "min                        0.000000    18.000000    10.000000     0.000000   \n",
       "25%                        0.240000    32.000000    20.000000     0.000000   \n",
       "50%                        0.490000    46.000000    30.000000     0.000000   \n",
       "75%                        0.740000    62.000000    40.000000     1.000000   \n",
       "max                        1.000000    75.000000    50.000000     1.000000   \n",
       "\n",
       "         Pregnancy      Smoking  Physical_activity  salt_content_in_the_diet  \\\n",
       "count  2000.000000  2000.000000        2000.000000               2000.000000   \n",
       "mean      0.649500     0.509500       25254.424500              24926.097000   \n",
       "std       0.882065     0.500035       14015.439623              14211.692586   \n",
       "min       0.000000     0.000000         628.000000                 22.000000   \n",
       "25%       0.000000     0.000000       13605.750000              13151.750000   \n",
       "50%       0.000000     1.000000       25353.000000              25046.500000   \n",
       "75%       2.000000     1.000000       37382.250000              36839.750000   \n",
       "max       2.000000     1.000000       49980.000000              49976.000000   \n",
       "\n",
       "       alcohol_consumption_per_day  Level_of_Stress  Chronic_kidney_disease  \\\n",
       "count                  2000.000000      2000.000000               2000.0000   \n",
       "mean                    250.886500         2.012500                  0.5050   \n",
       "std                     134.676589         0.823822                  0.5001   \n",
       "min                       0.000000         1.000000                  0.0000   \n",
       "25%                     144.000000         1.000000                  0.0000   \n",
       "50%                     250.000000         2.000000                  1.0000   \n",
       "75%                     360.250000         3.000000                  1.0000   \n",
       "max                     499.000000         3.000000                  1.0000   \n",
       "\n",
       "       Adrenal_and_thyroid_disorders  \n",
       "count                    2000.000000  \n",
       "mean                        0.443500  \n",
       "std                         0.496922  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         1.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_c = np.where(AF_train_df[\"Genetic_Pedigree_Coefficient\"].isnull(), \n",
    "                       0.49,                    \n",
    "                       AF_train_df[\"Genetic_Pedigree_Coefficient\"])\n",
    "AF_train_df[\"Genetic_Pedigree_Coefficient\"] = gen_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Number</th>\n",
       "      <th>Blood_Pressure_Abnormality</th>\n",
       "      <th>Level_of_Hemoglobin</th>\n",
       "      <th>Genetic_Pedigree_Coefficient</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pregnancy</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Physical_activity</th>\n",
       "      <th>salt_content_in_the_diet</th>\n",
       "      <th>alcohol_consumption_per_day</th>\n",
       "      <th>Level_of_Stress</th>\n",
       "      <th>Chronic_kidney_disease</th>\n",
       "      <th>Adrenal_and_thyroid_disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>11.710035</td>\n",
       "      <td>0.494595</td>\n",
       "      <td>46.558500</td>\n",
       "      <td>30.081500</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>25254.424500</td>\n",
       "      <td>24926.097000</td>\n",
       "      <td>250.886500</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>2.186701</td>\n",
       "      <td>0.284945</td>\n",
       "      <td>17.107832</td>\n",
       "      <td>11.761208</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>0.882065</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>14015.439623</td>\n",
       "      <td>14211.692586</td>\n",
       "      <td>134.676589</td>\n",
       "      <td>0.823822</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.147500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13605.750000</td>\n",
       "      <td>13151.750000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25353.000000</td>\n",
       "      <td>25046.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.945000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37382.250000</td>\n",
       "      <td>36839.750000</td>\n",
       "      <td>360.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49980.000000</td>\n",
       "      <td>49976.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_Number  Blood_Pressure_Abnormality  Level_of_Hemoglobin  \\\n",
       "count     2000.000000                 2000.000000          2000.000000   \n",
       "mean      1000.500000                    0.493500            11.710035   \n",
       "std        577.494589                    0.500083             2.186701   \n",
       "min          1.000000                    0.000000             8.100000   \n",
       "25%        500.750000                    0.000000            10.147500   \n",
       "50%       1000.500000                    0.000000            11.330000   \n",
       "75%       1500.250000                    1.000000            12.945000   \n",
       "max       2000.000000                    1.000000            17.560000   \n",
       "\n",
       "       Genetic_Pedigree_Coefficient          Age          BMI          Sex  \\\n",
       "count                   2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean                       0.494595    46.558500    30.081500     0.496000   \n",
       "std                        0.284945    17.107832    11.761208     0.500109   \n",
       "min                        0.000000    18.000000    10.000000     0.000000   \n",
       "25%                        0.250000    32.000000    20.000000     0.000000   \n",
       "50%                        0.490000    46.000000    30.000000     0.000000   \n",
       "75%                        0.730000    62.000000    40.000000     1.000000   \n",
       "max                        1.000000    75.000000    50.000000     1.000000   \n",
       "\n",
       "         Pregnancy      Smoking  Physical_activity  salt_content_in_the_diet  \\\n",
       "count  2000.000000  2000.000000        2000.000000               2000.000000   \n",
       "mean      0.649500     0.509500       25254.424500              24926.097000   \n",
       "std       0.882065     0.500035       14015.439623              14211.692586   \n",
       "min       0.000000     0.000000         628.000000                 22.000000   \n",
       "25%       0.000000     0.000000       13605.750000              13151.750000   \n",
       "50%       0.000000     1.000000       25353.000000              25046.500000   \n",
       "75%       2.000000     1.000000       37382.250000              36839.750000   \n",
       "max       2.000000     1.000000       49980.000000              49976.000000   \n",
       "\n",
       "       alcohol_consumption_per_day  Level_of_Stress  Chronic_kidney_disease  \\\n",
       "count                  2000.000000      2000.000000               2000.0000   \n",
       "mean                    250.886500         2.012500                  0.5050   \n",
       "std                     134.676589         0.823822                  0.5001   \n",
       "min                       0.000000         1.000000                  0.0000   \n",
       "25%                     144.000000         1.000000                  0.0000   \n",
       "50%                     250.000000         2.000000                  1.0000   \n",
       "75%                     360.250000         3.000000                  1.0000   \n",
       "max                     499.000000         3.000000                  1.0000   \n",
       "\n",
       "       Adrenal_and_thyroid_disorders  \n",
       "count                    2000.000000  \n",
       "mean                        0.443500  \n",
       "std                         0.496922  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         1.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit(AF_train_df)\n",
    "rescaled = scaler.transform(AF_train_df)\n",
    "\n",
    "AF_train_df =  pd.DataFrame(rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.381610</td>\n",
       "      <td>0.494595</td>\n",
       "      <td>0.501026</td>\n",
       "      <td>0.502038</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.324750</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.498995</td>\n",
       "      <td>0.498541</td>\n",
       "      <td>0.502779</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288892</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>0.231152</td>\n",
       "      <td>0.284945</td>\n",
       "      <td>0.300137</td>\n",
       "      <td>0.294030</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>0.441033</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.283989</td>\n",
       "      <td>0.284496</td>\n",
       "      <td>0.269893</td>\n",
       "      <td>0.411911</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.496922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216438</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262963</td>\n",
       "      <td>0.262837</td>\n",
       "      <td>0.288577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341438</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.500951</td>\n",
       "      <td>0.501002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.512156</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744737</td>\n",
       "      <td>0.737033</td>\n",
       "      <td>0.721944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.500000     0.493500     0.381610     0.494595     0.501026   \n",
       "std       0.288892     0.500083     0.231152     0.284945     0.300137   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.250000     0.000000     0.216438     0.250000     0.245614   \n",
       "50%       0.500000     0.000000     0.341438     0.490000     0.491228   \n",
       "75%       0.750000     1.000000     0.512156     0.730000     0.771930   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.502038     0.496000     0.324750     0.509500     0.498995   \n",
       "std       0.294030     0.500109     0.441033     0.500035     0.283989   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.250000     0.000000     0.000000     0.000000     0.262963   \n",
       "50%       0.500000     0.000000     0.000000     1.000000     0.500993   \n",
       "75%       0.750000     1.000000     1.000000     1.000000     0.744737   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                10           11           12         13           14  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.0000  2000.000000  \n",
       "mean      0.498541     0.502779     0.506250     0.5050     0.443500  \n",
       "std       0.284496     0.269893     0.411911     0.5001     0.496922  \n",
       "min       0.000000     0.000000     0.000000     0.0000     0.000000  \n",
       "25%       0.262837     0.288577     0.000000     0.0000     0.000000  \n",
       "50%       0.500951     0.501002     0.500000     1.0000     0.000000  \n",
       "75%       0.737033     0.721944     1.000000     1.0000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.0000     1.000000  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AF_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(AF_train_df.iloc[:,1:])\n",
    "X, Y = data[:,1:],data[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    stratify=Y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.72\n",
      "Accuracy of Logistic regression classifier on test set: 0.71\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "Y_train =Y_train.reshape(Y_train.shape[0],)\n",
    "Y_test =Y_test.reshape(Y_test.shape[0],)\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'solver':('newton-cg', 'lbfgs', 'sag', 'saga')}\n",
    "classifier = LogisticRegression()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB on training set: 0.86\n",
      "Accuracy of GaussianNB on test set: 0.86\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB().fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GaussianNB on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GaussianNB on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.86\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion':('gini','entropy'),'max_features':(None,'auto','sqrt','log2')}\n",
    "classifier = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier on training set: 1.00\n",
      "Accuracy of RandomForestClassifier on test set: 0.90\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10,50,100],'criterion':('gini','entropy'),'max_features':(None,'auto','sqrt','log2')}\n",
    "classifier = RandomForestClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of RandomForestClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForestClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GradientBoostingClassifier on training set: 0.94\n",
      "Accuracy of GradientBoostingClassifier on test set: 0.90\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features='auto', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[50,100,150,250],'loss' : ('deviance', 'exponential'),'max_features':('auto','sqrt','log2')}\n",
    "classifier = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GradientBoostingClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GradientBoostingClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNeighborsClassifier on training set: 0.79\n",
      "Accuracy of KNeighborsClassifier on test set: 0.72\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors':[3,5,7,10]}\n",
    "classifier = KNeighborsClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of KNeighborsClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of KNeighborsClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm on training set: 0.90\n",
      "Accuracy of svm on test set: 0.85\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'kernel' : ('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "classifier = svm.SVC()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of svm on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of svm on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of mlp on training set: 0.94\n",
      "Accuracy of mlp on test set: 0.86\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=1000, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'activation' : ('logistic', 'tanh', 'relu'),'solver' : ('sgd', 'adam'),'hidden_layer_sizes': [(1000), (200), (250)],}\n",
    "classifier = MLPClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of mlp on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of mlp on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.446e+00 3.449e-01 1.581e+00 5.561e-01 3.038e+00 1.381e+00 1.472e-01\n",
      " 4.654e-01 6.543e-02 1.074e-01 5.800e-02 1.824e+02 1.130e+02]\n",
      "2000\n",
      "[[0.336 0.281 0.325 1.    0.5   0.919 1.    1.   ]\n",
      " [0.174 0.632 0.575 1.    1.    0.516 0.    0.   ]\n",
      " [0.284 0.912 0.975 0.    0.    0.19  1.    0.   ]\n",
      " [0.307 0.93  1.    0.    0.    0.203 1.    0.   ]\n",
      " [0.642 0.596 0.225 0.    0.    0.304 0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=8)\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "X_new = fit.transform(X)\n",
    "print(len(X_new))\n",
    "# summarize selected features\n",
    "print(X_new[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y,\n",
    "                                                    stratify=Y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.73\n",
      "Accuracy of Logistic regression classifier on test set: 0.71\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      " \n",
      "Accuracy of GaussianNB on training set: 0.79\n",
      "Accuracy of GaussianNB on test set: 0.77\n",
      " \n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.67\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier on training set: 1.00\n",
      "Accuracy of RandomForestClassifier on test set: 0.76\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GradientBoostingClassifier on training set: 0.81\n",
      "Accuracy of GradientBoostingClassifier on test set: 0.77\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      " \n",
      "Accuracy of KNeighborsClassifier on training set: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNeighborsClassifier on test set: 0.72\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm on training set: 0.81\n",
      "Accuracy of svm on test set: 0.77\n",
      "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of mlp on training set: 0.80\n",
      "Accuracy of mlp on test set: 0.76\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=200, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "Y_train =Y_train.reshape(Y_train.shape[0],)\n",
    "Y_test =Y_test.reshape(Y_test.shape[0],)\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'solver':('newton-cg', 'lbfgs', 'sag', 'saga')}\n",
    "classifier = LogisticRegression()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print(' ')\n",
    "clf = GaussianNB().fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GaussianNB on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GaussianNB on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(' ')\n",
    "parameters = {'criterion':('gini','entropy'),'max_features':(None,'auto','sqrt','log2')}\n",
    "classifier = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'n_estimators':[10,50,100],'criterion':('gini','entropy'),'max_features':(None,'auto','sqrt','log2')}\n",
    "classifier = RandomForestClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of RandomForestClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForestClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'n_estimators':[50,100,150,250],'loss' : ('deviance', 'exponential'),'max_features':('auto','sqrt','log2')}\n",
    "classifier = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GradientBoostingClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GradientBoostingClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'n_neighbors':[3,5,7,10]}\n",
    "classifier = KNeighborsClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of KNeighborsClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of KNeighborsClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'kernel' : ('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "classifier = svm.SVC()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of svm on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of svm on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'activation' : ('logistic', 'tanh', 'relu'),'solver' : ('sgd', 'adam'),'hidden_layer_sizes': [(1000), (200), (250)],}\n",
    "classifier = MLPClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of mlp on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of mlp on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(AF_train_df.iloc[:,1:])\n",
    "X, Y = data[:,[1,2,4,7]],data[:,:1]\n",
    "print(X.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    stratify=Y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GradientBoostingClassifier on training set: 0.94\n",
      "Accuracy of GradientBoostingClassifier on test set: 0.87\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "              max_features='auto', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm on training set: 0.91\n",
      "Accuracy of svm on test set: 0.90\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of mlp on training set: 0.91\n",
      "Accuracy of mlp on test set: 0.89\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=250, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "Y_train =Y_train.reshape(Y_train.shape[0],)\n",
    "Y_test =Y_test.reshape(Y_test.shape[0],)\n",
    "\n",
    "parameters = {'n_estimators':[50,100,150,250],'loss' : ('deviance', 'exponential'),'max_features':('auto','sqrt','log2')}\n",
    "classifier = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of GradientBoostingClassifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of GradientBoostingClassifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'kernel' : ('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "classifier = svm.SVC()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of svm on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of svm on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)\n",
    "print(' ')\n",
    "parameters = {'activation' : ('logistic', 'tanh', 'relu'),'solver' : ('sgd', 'adam'),'hidden_layer_sizes': [(100), (200), (250)],}\n",
    "classifier = MLPClassifier()\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "testY_temp = clf.predict(X_test)\n",
    "print('Accuracy of mlp on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, Y_train)))\n",
    "print('Accuracy of mlp on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, Y_test)))\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
